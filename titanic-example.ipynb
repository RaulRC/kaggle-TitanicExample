{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.naive_bayes import BernoulliNB\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.csv', 'gender_submission.csv', 'test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "my_imputer = Imputer()\n\nfile_path = \"../input/train.csv\"\npath_test = \"../input/test.csv\"\ndata = pd.read_csv(file_path)\ndata_test = pd.read_csv(path_test)\n\ny = data['Survived']\nfeatures = ['Pclass','Sex', 'Age', 'SibSp','Parch', 'Fare']\nX = data[features]\n\ntest_X = data_test[features]\n\none_hot_encoded_X = pd.get_dummies(X)\nimputed_X = my_imputer.fit_transform(one_hot_encoded_X)\none_hot_encoded_test_X = pd.get_dummies(test_X)\nimputed_test_X = my_imputer.fit_transform(one_hot_encoded_test_X)\n\nrf_model = GradientBoostingClassifier()\nrf_model.fit(imputed_X, y)\nrf_predictions = rf_model.predict(imputed_test_X)\n#print( rf_model.score( val_X,val_y))\n#print(accuracy_score(test_y, rf_predictions))\n\n\noutput = pd.DataFrame({'PassengerId':data_test.PassengerId,'survived':rf_predictions})\noutput.to_csv('submission.csv',index = False)\n\n#plots = plot_partial_dependence(rf_model,features=[0,5],X=imputed_X )",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f48ff5e103b52d4ae600f44f182a90e929c8569b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}